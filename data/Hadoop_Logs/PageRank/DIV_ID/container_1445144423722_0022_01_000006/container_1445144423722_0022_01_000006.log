2015-10-18 18:02:00,494 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-18 18:02:00,713 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-18 18:02:00,713 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2015-10-18 18:02:00,729 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2015-10-18 18:02:00,729 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1445144423722_0022, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@3acd9e86)
2015-10-18 18:02:00,932 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2015-10-18 18:02:01,620 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445144423722_0022
2015-10-18 18:02:03,745 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2015-10-18 18:02:05,307 INFO [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
2015-10-18 18:02:05,635 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@e7d6ad
2015-10-18 18:02:09,292 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://msra-sa-41:9000/pageinput2.txt:536870912+134217728
2015-10-18 18:02:09,370 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-10-18 18:02:09,370 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-10-18 18:02:09,370 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-10-18 18:02:09,370 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-10-18 18:02:09,370 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-10-18 18:02:09,401 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-10-18 18:02:17,277 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 18:02:17,277 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 48250246; bufvoid = 104857600
2015-10-18 18:02:17,277 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 17305444(69221776); length = 8908953/6553600
2015-10-18 18:02:17,277 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 57318998 kvi 14329744(57318976)
2015-10-18 18:02:47,482 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 0
2015-10-18 18:02:47,529 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 57318998 kv 14329744(57318976) kvi 12130124(48520496)
2015-10-18 18:02:52,169 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 18:02:52,169 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 57318998; bufend = 707922; bufvoid = 104857599
2015-10-18 18:02:52,169 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 14329744(57318976); kvend = 5419856(21679424); length = 8909889/6553600
2015-10-18 18:02:52,169 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 9776658 kvi 2444160(9776640)
2015-10-18 18:03:19,906 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 1
2015-10-18 18:03:19,906 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 9776658 kv 2444160(9776640) kvi 247856(991424)
2015-10-18 18:03:24,796 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 18:03:24,796 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 9776658; bufend = 57994455; bufvoid = 104857600
2015-10-18 18:03:24,796 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 2444160(9776640); kvend = 19741496(78965984); length = 8917065/6553600
2015-10-18 18:03:24,796 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 67063207 kvi 16765796(67063184)
2015-10-18 18:03:57,486 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 2
2015-10-18 18:03:57,486 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 67063207 kv 16765796(67063184) kvi 14570840(58283360)
2015-10-18 18:04:01,596 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 18:04:01,596 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 67063207; bufend = 10480387; bufvoid = 104857600
2015-10-18 18:04:01,596 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 16765796(67063184); kvend = 7862980(31451920); length = 8902817/6553600
2015-10-18 18:04:01,596 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 19549139 kvi 4887280(19549120)
2015-10-18 18:04:30,941 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 3
2015-10-18 18:04:31,129 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 19549139 kv 4887280(19549120) kvi 2679652(10718608)
2015-10-18 18:04:35,519 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 18:04:35,519 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 19549139; bufend = 67751785; bufvoid = 104857600
2015-10-18 18:04:35,519 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 4887280(19549120); kvend = 22180828(88723312); length = 8920853/6553600
2015-10-18 18:04:35,519 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 76820537 kvi 19205128(76820512)
2015-10-18 18:05:02,177 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 4
2015-10-18 18:05:02,193 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 76820537 kv 19205128(76820512) kvi 16995388(67981552)
2015-10-18 18:05:24,491 INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/127.0.0.1"; destination host is: "10.190.173.170":29630; 
2015-10-18 18:05:24,	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
2015-10-18 18:05:24,	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
2015-10-18 18:05:24,	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
2015-10-18 18:05:24,	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
2015-10-18 18:05:24,	at com.sun.proxy.$Proxy9.statusUpdate(Unknown Source)
2015-10-18 18:05:24,	at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:737)
2015-10-18 18:05:24,	at java.lang.Thread.run(Thread.java:724)
2015-10-18 18:05:24,Caused by: java.io.IOException: An existing connection was forcibly closed by the remote host
2015-10-18 18:05:24,	at sun.nio.ch.SocketDispatcher.read0(Native Method)
2015-10-18 18:05:24,	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
2015-10-18 18:05:24,	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
2015-10-18 18:05:24,	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
2015-10-18 18:05:24,	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
2015-10-18 18:05:24,	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
2015-10-18 18:05:24,	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
2015-10-18 18:05:24,	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
2015-10-18 18:05:24,	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
2015-10-18 18:05:24,	at java.io.FilterInputStream.read(FilterInputStream.java:133)
2015-10-18 18:05:24,	at java.io.FilterInputStream.read(FilterInputStream.java:133)
2015-10-18 18:05:24,	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:513)
2015-10-18 18:05:24,	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
2015-10-18 18:05:24,	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
2015-10-18 18:05:24,	at java.io.DataInputStream.readInt(DataInputStream.java:387)
2015-10-18 18:05:24,	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1071)
2015-10-18 18:05:24,	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:966)
2015-10-18 18:05:24,
2015-10-18 18:05:28,523 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:29,538 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:30,538 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:31,539 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:32,539 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:33,539 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:34,539 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:35,539 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:36,539 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:37,539 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:37,539 INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to 10.190.173.170:29630 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:05:37,	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
2015-10-18 18:05:37,	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
2015-10-18 18:05:37,	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
2015-10-18 18:05:37,	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
2015-10-18 18:05:37,	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
2015-10-18 18:05:37,	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
2015-10-18 18:05:37,	at com.sun.proxy.$Proxy9.statusUpdate(Unknown Source)
2015-10-18 18:05:37,	at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:737)
2015-10-18 18:05:37,	at java.lang.Thread.run(Thread.java:724)
2015-10-18 18:05:37,Caused by: java.net.NoRouteToHostException: No route to host: no further information
2015-10-18 18:05:37,	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2015-10-18 18:05:37,	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)
2015-10-18 18:05:37,	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
2015-10-18 18:05:37,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
2015-10-18 18:05:37,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
2015-10-18 18:05:37,	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
2015-10-18 18:05:37,	... 5 more
2015-10-18 18:05:37,
2015-10-18 18:05:41,555 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:42,570 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:43,571 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:44,571 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:45,571 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:46,571 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:47,571 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:48,571 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:49,571 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:50,587 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:05:50,587 INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to 10.190.173.170:29630 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:05:50,	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
2015-10-18 18:05:50,	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
2015-10-18 18:05:50,	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
2015-10-18 18:05:50,	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
2015-10-18 18:05:50,	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
2015-10-18 18:05:50,	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
2015-10-18 18:05:50,	at com.sun.proxy.$Proxy9.statusUpdate(Unknown Source)
2015-10-18 18:05:50,	at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:737)
2015-10-18 18:05:50,	at java.lang.Thread.run(Thread.java:724)
2015-10-18 18:05:50,Caused by: java.net.NoRouteToHostException: No route to host: no further information
2015-10-18 18:05:50,	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2015-10-18 18:05:50,	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)
2015-10-18 18:05:50,	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
2015-10-18 18:05:50,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
2015-10-18 18:05:50,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
2015-10-18 18:05:50,	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
2015-10-18 18:05:50,	... 5 more
2015-10-18 18:05:50,
2015-10-18 18:05:50,587 INFO [communication thread] org.apache.hadoop.mapred.Task: Process Thread Dump: Communication exception
2015-10-18 18:05:50,12 active threads
2015-10-18 18:05:50,Thread 21 (SpillThread):
2015-10-18 18:05:50,  State: WAITING
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 6
2015-10-18 18:05:50,  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@2e498b1
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    sun.misc.Unsafe.park(Native Method)
2015-10-18 18:05:50,    java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
2015-10-18 18:05:50,    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
2015-10-18 18:05:50,    org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1521)
2015-10-18 18:05:50,Thread 20 (org.apache.hadoop.hdfs.PeerCache@60ec1f20):
2015-10-18 18:05:50,  State: TIMED_WAITING
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 74
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    java.lang.Thread.sleep(Native Method)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:244)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:41)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:119)
2015-10-18 18:05:50,    java.lang.Thread.run(Thread.java:724)
2015-10-18 18:05:50,Thread 16 (communication thread):
2015-10-18 18:05:50,  State: RUNNABLE
2015-10-18 18:05:50,  Blocked count: 58
2015-10-18 18:05:50,  Waited count: 179
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    sun.management.ThreadImpl.getThreadInfo1(Native Method)
2015-10-18 18:05:50,    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:174)
2015-10-18 18:05:50,    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:139)
2015-10-18 18:05:50,    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:165)
2015-10-18 18:05:50,    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:219)
2015-10-18 18:05:50,    org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:760)
2015-10-18 18:05:50,    java.lang.Thread.run(Thread.java:724)
2015-10-18 18:05:50,Thread 15 (Thread for syncLogs):
2015-10-18 18:05:50,  State: TIMED_WAITING
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 56
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    sun.misc.Unsafe.park(Native Method)
2015-10-18 18:05:50,    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
2015-10-18 18:05:50,    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
2015-10-18 18:05:50,    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)
2015-10-18 18:05:50,    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
2015-10-18 18:05:50,    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
2015-10-18 18:05:50,    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
2015-10-18 18:05:50,    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
2015-10-18 18:05:50,    java.lang.Thread.run(Thread.java:724)
2015-10-18 18:05:50,Thread 13 (IPC Parameter Sending Thread #0):
2015-10-18 18:05:50,  State: TIMED_WAITING
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 54
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    sun.misc.Unsafe.park(Native Method)
2015-10-18 18:05:50,    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
2015-10-18 18:05:50,    java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
2015-10-18 18:05:50,    java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:359)
2015-10-18 18:05:50,    java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:942)
2015-10-18 18:05:50,    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
2015-10-18 18:05:50,    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
2015-10-18 18:05:50,    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
2015-10-18 18:05:50,    java.lang.Thread.run(Thread.java:724)
2015-10-18 18:05:50,Thread 11 (Timer for 'MapTask' metrics system):
2015-10-18 18:05:50,  State: TIMED_WAITING
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 23
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    java.lang.Object.wait(Native Method)
2015-10-18 18:05:50,    java.util.TimerThread.mainLoop(Timer.java:552)
2015-10-18 18:05:50,    java.util.TimerThread.run(Timer.java:505)
2015-10-18 18:05:50,Thread 10 (Thread-1):
2015-10-18 18:05:50,  State: RUNNABLE
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 0
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    sun.net.dns.ResolverConfigurationImpl.notifyAddrChange0(Native Method)
2015-10-18 18:05:50,    sun.net.dns.ResolverConfigurationImpl$AddressChangeListener.run(ResolverConfigurationImpl.java:142)
2015-10-18 18:05:50,Thread 5 (Attach Listener):
2015-10-18 18:05:50,  State: RUNNABLE
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 0
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,Thread 4 (Signal Dispatcher):
2015-10-18 18:05:50,  State: RUNNABLE
2015-10-18 18:05:50,  Blocked count: 0
2015-10-18 18:05:50,  Waited count: 0
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,Thread 3 (Finalizer):
2015-10-18 18:05:50,  State: WAITING
2015-10-18 18:05:50,  Blocked count: 120
2015-10-18 18:05:50,  Waited count: 20
2015-10-18 18:05:50,  Waiting on java.lang.ref.ReferenceQueue$Lock@3c1473d0
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    java.lang.Object.wait(Native Method)
2015-10-18 18:05:50,    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
2015-10-18 18:05:50,    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
2015-10-18 18:05:50,    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189)
2015-10-18 18:05:50,Thread 2 (Reference Handler):
2015-10-18 18:05:50,  State: WAITING
2015-10-18 18:05:50,  Blocked count: 21
2015-10-18 18:05:50,  Waited count: 22
2015-10-18 18:05:50,  Waiting on java.lang.ref.Reference$Lock@62bf7b80
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    java.lang.Object.wait(Native Method)
2015-10-18 18:05:50,    java.lang.Object.wait(Object.java:503)
2015-10-18 18:05:50,    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
2015-10-18 18:05:50,Thread 1 (main):
2015-10-18 18:05:50,  State: RUNNABLE
2015-10-18 18:05:50,  Blocked count: 4
2015-10-18 18:05:50,  Waited count: 12
2015-10-18 18:05:50,  Stack:
2015-10-18 18:05:50,    sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
2015-10-18 18:05:50,    sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296)
2015-10-18 18:05:50,    sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278)
2015-10-18 18:05:50,    sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159)
2015-10-18 18:05:50,    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
2015-10-18 18:05:50,    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
2015-10-18 18:05:50,    org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
2015-10-18 18:05:50,    org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
2015-10-18 18:05:50,    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.readChannelFully(PacketReceiver.java:258)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:209)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:171)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:102)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.RemoteBlockReader2.readNextPacket(RemoteBlockReader2.java:186)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:146)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.DFSInputStream$ByteArrayStrategy.doRead(DFSInputStream.java:693)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:749)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:806)
2015-10-18 18:05:50,    org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:847)
2015-10-18 18:05:50,    java.io.DataInputStream.read(DataInputStream.java:100)
2015-10-18 18:05:50,
2015-10-18 18:05:50,587 WARN [communication thread] org.apache.hadoop.mapred.Task: Last retry, killing attempt_1445144423722_0022_m_000004_0
