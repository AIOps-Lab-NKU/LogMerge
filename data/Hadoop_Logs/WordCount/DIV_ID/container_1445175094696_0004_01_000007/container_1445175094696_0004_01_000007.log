2015-10-18 21:37:39,552 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-10-18 21:37:39,739 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-10-18 21:37:39,739 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2015-10-18 21:37:39,786 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2015-10-18 21:37:39,802 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1445175094696_0004, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@5d3cb6cf)
2015-10-18 21:37:40,177 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2015-10-18 21:37:41,427 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445175094696_0004
2015-10-18 21:37:42,943 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2015-10-18 21:37:45,724 INFO [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
2015-10-18 21:37:46,224 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b8a4c9d
2015-10-18 21:37:51,505 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://msra-sa-41:9000/wordcount2.txt:671088640+134217728
2015-10-18 21:37:51,662 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-10-18 21:37:51,662 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-10-18 21:37:51,662 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-10-18 21:37:51,662 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-10-18 21:37:51,662 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-10-18 21:37:51,693 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-10-18 21:38:09,850 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 21:38:09,850 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 34177286; bufvoid = 104857600
2015-10-18 21:38:09,850 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 13787204(55148816); length = 12427193/6553600
2015-10-18 21:38:09,850 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 44663043 kvi 11165756(44663024)
2015-10-18 21:38:38,633 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 0
2015-10-18 21:38:38,664 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 44663043 kv 11165756(44663024) kvi 8544328(34177312)
2015-10-18 21:38:43,149 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 21:38:43,149 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 44663043; bufend = 78834546; bufvoid = 104857600
2015-10-18 21:38:43,149 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 11165756(44663024); kvend = 24951520(99806080); length = 12428637/6553600
2015-10-18 21:38:43,149 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 89320305 kvi 22330072(89320288)
2015-10-18 21:38:55,493 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 1
2015-10-18 21:38:55,509 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 89320305 kv 22330072(89320288) kvi 19708644(78834576)
2015-10-18 21:39:00,759 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2015-10-18 21:39:00,759 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 89320305; bufend = 18636739; bufvoid = 104857592
2015-10-18 21:39:00,759 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 22330072(89320288); kvend = 9902068(39608272); length = 12428005/6553600
2015-10-18 21:39:00,759 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 29122497 kvi 7280620(29122480)
2015-10-18 21:39:20,635 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 2
2015-10-18 21:39:20,650 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 29122497 kv 7280620(29122480) kvi 4659192(18636768)
2015-10-18 21:39:40,421 INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/127.0.0.1"; destination host is: "10.190.173.170":25859; 
2015-10-18 21:39:40,	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
2015-10-18 21:39:40,	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
2015-10-18 21:39:40,	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
2015-10-18 21:39:40,	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
2015-10-18 21:39:40,	at com.sun.proxy.$Proxy9.statusUpdate(Unknown Source)
2015-10-18 21:39:40,	at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:737)
2015-10-18 21:39:40,	at java.lang.Thread.run(Thread.java:724)
2015-10-18 21:39:40,Caused by: java.io.IOException: An existing connection was forcibly closed by the remote host
2015-10-18 21:39:40,	at sun.nio.ch.SocketDispatcher.read0(Native Method)
2015-10-18 21:39:40,	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
2015-10-18 21:39:40,	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
2015-10-18 21:39:40,	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
2015-10-18 21:39:40,	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
2015-10-18 21:39:40,	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
2015-10-18 21:39:40,	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
2015-10-18 21:39:40,	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
2015-10-18 21:39:40,	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
2015-10-18 21:39:40,	at java.io.FilterInputStream.read(FilterInputStream.java:133)
2015-10-18 21:39:40,	at java.io.FilterInputStream.read(FilterInputStream.java:133)
2015-10-18 21:39:40,	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:513)
2015-10-18 21:39:40,	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
2015-10-18 21:39:40,	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
2015-10-18 21:39:40,	at java.io.DataInputStream.readInt(DataInputStream.java:387)
2015-10-18 21:39:40,	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1071)
2015-10-18 21:39:40,	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:966)
2015-10-18 21:39:40,
2015-10-18 21:39:44,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:45,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:46,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:47,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:48,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:49,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:50,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:51,452 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:52,453 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:53,453 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:53,453 INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to 10.190.173.170:25859 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 21:39:53,	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
2015-10-18 21:39:53,	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
2015-10-18 21:39:53,	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
2015-10-18 21:39:53,	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
2015-10-18 21:39:53,	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
2015-10-18 21:39:53,	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
2015-10-18 21:39:53,	at com.sun.proxy.$Proxy9.statusUpdate(Unknown Source)
2015-10-18 21:39:53,	at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:737)
2015-10-18 21:39:53,	at java.lang.Thread.run(Thread.java:724)
2015-10-18 21:39:53,Caused by: java.net.NoRouteToHostException: No route to host: no further information
2015-10-18 21:39:53,	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2015-10-18 21:39:53,	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)
2015-10-18 21:39:53,	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
2015-10-18 21:39:53,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
2015-10-18 21:39:53,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
2015-10-18 21:39:53,	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
2015-10-18 21:39:53,	... 5 more
2015-10-18 21:39:53,
2015-10-18 21:39:57,500 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:58,515 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:39:59,515 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:00,515 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:01,515 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:02,516 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:03,516 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:04,516 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:05,516 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:06,516 INFO [communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: 10.190.173.170/10.190.173.170:25859. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 21:40:06,516 INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to 10.190.173.170:25859 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 21:40:06,	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
2015-10-18 21:40:06,	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
2015-10-18 21:40:06,	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
2015-10-18 21:40:06,	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
2015-10-18 21:40:06,	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
2015-10-18 21:40:06,	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
2015-10-18 21:40:06,	at com.sun.proxy.$Proxy9.statusUpdate(Unknown Source)
2015-10-18 21:40:06,	at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:737)
2015-10-18 21:40:06,	at java.lang.Thread.run(Thread.java:724)
2015-10-18 21:40:06,Caused by: java.net.NoRouteToHostException: No route to host: no further information
2015-10-18 21:40:06,	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
2015-10-18 21:40:06,	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)
2015-10-18 21:40:06,	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
2015-10-18 21:40:06,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
2015-10-18 21:40:06,	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
2015-10-18 21:40:06,	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
2015-10-18 21:40:06,	... 5 more
2015-10-18 21:40:06,
2015-10-18 21:40:06,516 INFO [communication thread] org.apache.hadoop.mapred.Task: Process Thread Dump: Communication exception
2015-10-18 21:40:06,12 active threads
2015-10-18 21:40:06,Thread 21 (SpillThread):
2015-10-18 21:40:06,  State: WAITING
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 4
2015-10-18 21:40:06,  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@220336f0
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    sun.misc.Unsafe.park(Native Method)
2015-10-18 21:40:06,    java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
2015-10-18 21:40:06,    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
2015-10-18 21:40:06,    org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1521)
2015-10-18 21:40:06,Thread 20 (org.apache.hadoop.hdfs.PeerCache@891c3e3):
2015-10-18 21:40:06,  State: TIMED_WAITING
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 45
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    java.lang.Thread.sleep(Native Method)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:244)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:41)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:119)
2015-10-18 21:40:06,    java.lang.Thread.run(Thread.java:724)
2015-10-18 21:40:06,Thread 16 (communication thread):
2015-10-18 21:40:06,  State: RUNNABLE
2015-10-18 21:40:06,  Blocked count: 31
2015-10-18 21:40:06,  Waited count: 104
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    sun.management.ThreadImpl.getThreadInfo1(Native Method)
2015-10-18 21:40:06,    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:174)
2015-10-18 21:40:06,    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:139)
2015-10-18 21:40:06,    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:165)
2015-10-18 21:40:06,    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:219)
2015-10-18 21:40:06,    org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:760)
2015-10-18 21:40:06,    java.lang.Thread.run(Thread.java:724)
2015-10-18 21:40:06,Thread 15 (Thread for syncLogs):
2015-10-18 21:40:06,  State: TIMED_WAITING
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 34
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    sun.misc.Unsafe.park(Native Method)
2015-10-18 21:40:06,    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
2015-10-18 21:40:06,    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
2015-10-18 21:40:06,    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)
2015-10-18 21:40:06,    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
2015-10-18 21:40:06,    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
2015-10-18 21:40:06,    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
2015-10-18 21:40:06,    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
2015-10-18 21:40:06,    java.lang.Thread.run(Thread.java:724)
2015-10-18 21:40:06,Thread 13 (IPC Parameter Sending Thread #0):
2015-10-18 21:40:06,  State: TIMED_WAITING
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 31
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    sun.misc.Unsafe.park(Native Method)
2015-10-18 21:40:06,    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
2015-10-18 21:40:06,    java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
2015-10-18 21:40:06,    java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:359)
2015-10-18 21:40:06,    java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:942)
2015-10-18 21:40:06,    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
2015-10-18 21:40:06,    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
2015-10-18 21:40:06,    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
2015-10-18 21:40:06,    java.lang.Thread.run(Thread.java:724)
2015-10-18 21:40:06,Thread 11 (Timer for 'MapTask' metrics system):
2015-10-18 21:40:06,  State: TIMED_WAITING
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 15
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    java.lang.Object.wait(Native Method)
2015-10-18 21:40:06,    java.util.TimerThread.mainLoop(Timer.java:552)
2015-10-18 21:40:06,    java.util.TimerThread.run(Timer.java:505)
2015-10-18 21:40:06,Thread 10 (Thread-1):
2015-10-18 21:40:06,  State: RUNNABLE
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 0
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    sun.net.dns.ResolverConfigurationImpl.notifyAddrChange0(Native Method)
2015-10-18 21:40:06,    sun.net.dns.ResolverConfigurationImpl$AddressChangeListener.run(ResolverConfigurationImpl.java:142)
2015-10-18 21:40:06,Thread 5 (Attach Listener):
2015-10-18 21:40:06,  State: RUNNABLE
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 0
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,Thread 4 (Signal Dispatcher):
2015-10-18 21:40:06,  State: RUNNABLE
2015-10-18 21:40:06,  Blocked count: 0
2015-10-18 21:40:06,  Waited count: 0
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,Thread 3 (Finalizer):
2015-10-18 21:40:06,  State: WAITING
2015-10-18 21:40:06,  Blocked count: 33
2015-10-18 21:40:06,  Waited count: 17
2015-10-18 21:40:06,  Waiting on java.lang.ref.ReferenceQueue$Lock@2eb4ada3
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    java.lang.Object.wait(Native Method)
2015-10-18 21:40:06,    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
2015-10-18 21:40:06,    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
2015-10-18 21:40:06,    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189)
2015-10-18 21:40:06,Thread 2 (Reference Handler):
2015-10-18 21:40:06,  State: WAITING
2015-10-18 21:40:06,  Blocked count: 18
2015-10-18 21:40:06,  Waited count: 18
2015-10-18 21:40:06,  Waiting on java.lang.ref.Reference$Lock@57f3c049
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    java.lang.Object.wait(Native Method)
2015-10-18 21:40:06,    java.lang.Object.wait(Object.java:503)
2015-10-18 21:40:06,    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
2015-10-18 21:40:06,Thread 1 (main):
2015-10-18 21:40:06,  State: RUNNABLE
2015-10-18 21:40:06,  Blocked count: 4
2015-10-18 21:40:06,  Waited count: 11
2015-10-18 21:40:06,  Stack:
2015-10-18 21:40:06,    sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
2015-10-18 21:40:06,    sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296)
2015-10-18 21:40:06,    sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278)
2015-10-18 21:40:06,    sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159)
2015-10-18 21:40:06,    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
2015-10-18 21:40:06,    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
2015-10-18 21:40:06,    org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
2015-10-18 21:40:06,    org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
2015-10-18 21:40:06,    org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.readChannelFully(PacketReceiver.java:258)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:209)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:171)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:102)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.RemoteBlockReader2.readNextPacket(RemoteBlockReader2.java:186)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:146)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.DFSInputStream$ByteArrayStrategy.doRead(DFSInputStream.java:693)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:749)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:806)
2015-10-18 21:40:06,    org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:847)
2015-10-18 21:40:06,    java.io.DataInputStream.read(DataInputStream.java:100)
2015-10-18 21:40:06,
2015-10-18 21:40:06,516 WARN [communication thread] org.apache.hadoop.mapred.Task: Last retry, killing attempt_1445175094696_0004_m_000005_0
